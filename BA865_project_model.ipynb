{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "g"
      ],
      "metadata": {
        "id": "PrDLOJt1UdE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MRg31yJ2xMB"
      },
      "source": [
        "## Predicting the Number of  People Have Tried the Recipe Based on the Food Recipes Data\n",
        "\n",
        "#### BA 865 \n",
        "\n",
        "#### Team members: Zixing Li, Hanyu Chen, Mengxin Li, Yapei Xiong"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8K_CXHxG20Iu",
        "outputId": "9cd3cec4-caac-4a58-8bc1-a90729acac1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-plot\n",
            "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.0.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (3.0.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.21.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->scikit-plot) (3.1.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n",
            "Collecting textdescriptives\n",
            "  Downloading textdescriptives-1.0.6-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from textdescriptives) (1.3.5)\n",
            "Collecting pyphen>=0.11.0\n",
            "  Downloading pyphen-0.12.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 8.4 MB/s \n",
            "\u001b[?25hCollecting spacy>=3.0.3\n",
            "  Downloading spacy-3.2.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 46.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from textdescriptives) (1.21.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.0->textdescriptives) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.0->textdescriptives) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.0->textdescriptives) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.3->textdescriptives) (3.10.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.3->textdescriptives) (57.4.0)\n",
            "Collecting thinc<8.1.0,>=8.0.12\n",
            "  Downloading thinc-8.0.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (653 kB)\n",
            "\u001b[K     |████████████████████████████████| 653 kB 55.4 MB/s \n",
            "\u001b[?25hCollecting typer<0.5.0,>=0.3.0\n",
            "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 39.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.3->textdescriptives) (4.63.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.3->textdescriptives) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.3->textdescriptives) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.3->textdescriptives) (3.0.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.3->textdescriptives) (2.11.3)\n",
            "Collecting langcodes<4.0.0,>=3.2.0\n",
            "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 61.4 MB/s \n",
            "\u001b[?25hCollecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.3->textdescriptives) (1.0.6)\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 55.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.3->textdescriptives) (21.3)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
            "  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.3->textdescriptives) (2.0.6)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
            "  Downloading spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.3->textdescriptives) (0.9.0)\n",
            "Collecting catalogue<2.1.0,>=2.0.6\n",
            "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy>=3.0.3->textdescriptives) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy>=3.0.3->textdescriptives) (3.0.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy>=3.0.3->textdescriptives) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.3->textdescriptives) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.3->textdescriptives) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.3->textdescriptives) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.3->textdescriptives) (2.10)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy>=3.0.3->textdescriptives) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy>=3.0.3->textdescriptives) (2.0.1)\n",
            "Installing collected packages: catalogue, typer, srsly, pydantic, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy, pyphen, textdescriptives\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.6 langcodes-3.3.0 pathy-0.6.1 pydantic-1.8.2 pyphen-0.12.0 spacy-3.2.3 spacy-legacy-3.0.9 spacy-loggers-1.0.1 srsly-2.4.2 textdescriptives-1.0.6 thinc-8.0.15 typer-0.4.0\n",
            "Collecting tokenwiser\n",
            "  Downloading tokenwiser-0.1.7-py2.py3-none-any.whl (30 kB)\n",
            "Collecting PyYAML>=5.3.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tokenwiser) (3.2.3)\n",
            "Collecting vowpalwabbit>=8.9.0\n",
            "  Downloading vowpalwabbit-9.0.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 24.4 MB/s \n",
            "\u001b[?25hCollecting jellyfish>=0.8.2\n",
            "  Downloading jellyfish-0.9.0.tar.gz (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 54.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pyphen>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from tokenwiser) (0.12.0)\n",
            "Requirement already satisfied: snowballstemmer>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tokenwiser) (2.2.0)\n",
            "Collecting yake-github>=0.4.0\n",
            "  Downloading yake-github-0.4.0.tar.gz (390 kB)\n",
            "\u001b[K     |████████████████████████████████| 390 kB 38.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from tokenwiser) (1.0.2)\n",
            "Collecting sentencepiece>=0.1.95\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 49.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.0->tokenwiser) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.0->tokenwiser) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.0->tokenwiser) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.0->tokenwiser) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.1.0->tokenwiser) (3.10.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.1.0->tokenwiser) (2.23.0)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.1.0->tokenwiser) (0.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.1.0->tokenwiser) (3.0.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.1.0->tokenwiser) (1.8.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.1.0->tokenwiser) (2.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.1.0->tokenwiser) (2.11.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.1.0->tokenwiser) (2.0.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.1.0->tokenwiser) (21.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.1.0->tokenwiser) (0.6.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.1.0->tokenwiser) (0.9.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.1.0->tokenwiser) (3.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.1.0->tokenwiser) (4.63.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=3.1.0->tokenwiser) (57.4.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.1.0->tokenwiser) (1.0.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.1.0->tokenwiser) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.1.0->tokenwiser) (8.0.15)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.1.0->tokenwiser) (1.0.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.1.0->tokenwiser) (2.0.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.1.0->tokenwiser) (0.4.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy>=3.1.0->tokenwiser) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy>=3.1.0->tokenwiser) (3.0.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy>=3.1.0->tokenwiser) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.1.0->tokenwiser) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.1.0->tokenwiser) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.1.0->tokenwiser) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.1.0->tokenwiser) (2.10)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy>=3.1.0->tokenwiser) (7.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from yake-github>=0.4.0->tokenwiser) (0.8.9)\n",
            "Collecting segtok\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from yake-github>=0.4.0->tokenwiser) (2.6.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy>=3.1.0->tokenwiser) (2.0.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from segtok->yake-github>=0.4.0->tokenwiser) (2019.12.20)\n",
            "Building wheels for collected packages: jellyfish, yake-github\n",
            "  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jellyfish: filename=jellyfish-0.9.0-cp37-cp37m-linux_x86_64.whl size=73996 sha256=054476ca5b501c4762e0ca40e05ef1bff3d5929296dcffcc9c57bfbb317d1fe3\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/99/4e/646ce766df0d070b0ef04db27aa11543e2767fda3075aec31b\n",
            "  Building wheel for yake-github (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yake-github: filename=yake_github-0.4.0-py2.py3-none-any.whl size=56625 sha256=0e73b42d8ceb6dc6248fa1292593c758347fe341f43258dc7aa032a6a4826713\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/55/0e/edbca8d3acb7fd3b22149e8940c5d003ec8d2ee26671da6fdf\n",
            "Successfully built jellyfish yake-github\n",
            "Installing collected packages: segtok, jellyfish, yake-github, vowpalwabbit, sentencepiece, PyYAML, tokenwiser\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-6.0 jellyfish-0.9.0 segtok-1.5.11 sentencepiece-0.1.96 tokenwiser-0.1.7 vowpalwabbit-9.0.1 yake-github-0.4.0\n",
            "Collecting spacytextblob\n",
            "  Downloading spacytextblob-4.0.0-py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: spacy<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from spacytextblob) (3.2.3)\n",
            "Requirement already satisfied: textblob<0.16.0,>=0.15.3 in /usr/local/lib/python3.7/dist-packages (from spacytextblob) (0.15.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (3.0.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (21.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (2.11.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (2.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (2.0.6)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (1.0.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (1.21.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (3.0.9)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (4.63.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (1.0.6)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (3.10.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (0.9.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (3.3.0)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (8.0.15)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (2.4.2)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (0.4.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (0.6.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=3.0->spacytextblob) (1.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<4.0,>=3.0->spacytextblob) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<4.0,>=3.0->spacytextblob) (3.0.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<4.0,>=3.0->spacytextblob) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0,>=3.0->spacytextblob) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0,>=3.0->spacytextblob) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0,>=3.0->spacytextblob) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0,>=3.0->spacytextblob) (3.0.4)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob<0.16.0,>=0.15.3->spacytextblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob<0.16.0,>=0.15.3->spacytextblob) (1.15.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<4.0,>=3.0->spacytextblob) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<4.0,>=3.0->spacytextblob) (2.0.1)\n",
            "Installing collected packages: spacytextblob\n",
            "Successfully installed spacytextblob-4.0.0\n"
          ]
        }
      ],
      "source": [
        "#installs\n",
        "! pip install scikit-plot\n",
        "! pip install textdescriptives\n",
        "! pip install tokenwiser\n",
        "! pip install spacytextblob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tftUKmKj21gw",
        "outputId": "096526dd-e3ee-42f9-8924-7157554385b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# imports\n",
        "from sklearn.datasets import load_digits, fetch_openml, make_blobs\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import uuid\n",
        "import random\n",
        "\n",
        "# sklearn does have some functionality too, but mostly a wrapper to scipy\n",
        "from sklearn.metrics import pairwise_distances \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import scikitplot as skplt\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# text imports\n",
        "import spacy\n",
        "from spacytextblob.spacytextblob import SpacyTextBlob\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer,TfidfVectorizer  \n",
        "import nltk\n",
        "\n",
        "\n",
        "# text imports\n",
        "from spacy import cli\n",
        "import textdescriptives as td\n",
        "import tokenwiser\n",
        "from sklearn.pipeline import Pipeline\n",
        "nltk.download('punkt')\n",
        "import gensim\n",
        "\n",
        "import re\n",
        "\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjEpBXJrAEr9"
      },
      "source": [
        "# Data cleaning "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8oFpd6SDnLw",
        "outputId": "9d852ff2-23f4-4fcb-db1c-1a2a57c0ffc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1B23pVz9w9Y"
      },
      "outputs": [],
      "source": [
        "## Importing recipe data from local\n",
        "#df=pd.read_csv(\"/content/drive/MyDrive/food_recipes_data.csv\")\n",
        "#df = pd.read_csv('/content/drive/MyDrive/875 supply chain/dataset/food_recipes_data.csv') #Penny\n",
        "df = pd. read_csv(\"food_recipes_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rq0j6gAx_9tN",
        "outputId": "c27ddd00-79a5-4fee-dbd3-524303319763"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14200, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6d225eYAaiG",
        "outputId": "ba3a9d85-c37a-4874-b080-4f3a5fdd5867"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "total_time         2011\n",
              "cook_time          3859\n",
              "serving            2076\n",
              "crawled_at            0\n",
              "description           0\n",
              "title                 0\n",
              "url                   0\n",
              "nutritions_info    2197\n",
              "image                 0\n",
              "ingredients         137\n",
              "uniq_id               0\n",
              "source                0\n",
              "author                0\n",
              "prep_time          3090\n",
              "published_date        0\n",
              "keywords            360\n",
              "total_ratings        53\n",
              "instructions       1959\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "2CezFuErAdO4",
        "outputId": "a55c2632-1ee4-4988-efbc-dd8019bf0547"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  total_time cook_time serving           crawled_at  \\\n",
              "0      PT10M       NaN      14  2021-12-17 08:46:25   \n",
              "1      PT55M     PT30M       2  2021-12-17 01:49:12   \n",
              "2      PT30M     PT20M       4  2021-12-17 02:50:12   \n",
              "\n",
              "                                         description  \\\n",
              "0  Create a delicious homemade chocolate bark wit...   \n",
              "1  Steak and chips gets even more special with ra...   \n",
              "2  A dish with added feelgood factor - this vitam...   \n",
              "\n",
              "                                               title  \\\n",
              "0                                Easy chocolate bark   \n",
              "1  Venison steaks with stroganoff sauce & shoestr...   \n",
              "2                   Mexican chicken & wild rice soup   \n",
              "\n",
              "                                                 url  \\\n",
              "0  https://www.bbcgoodfood.com/recipes/easy-choco...   \n",
              "1  https://www.bbcgoodfood.com/recipes/venison-st...   \n",
              "2  https://www.bbcgoodfood.com/recipes/mexican-ch...   \n",
              "\n",
              "                                     nutritions_info  \\\n",
              "0  calories:116 calories | fatContent:7 grams fat...   \n",
              "1  calories:719 calories | fatContent:33 grams fa...   \n",
              "2  calories:347 calories | fatContent:7 grams fat...   \n",
              "\n",
              "                                               image  \\\n",
              "0  https://images.immediate.co.uk/production/vola...   \n",
              "1  https://images.immediate.co.uk/production/vola...   \n",
              "2  https://images.immediate.co.uk/production/vola...   \n",
              "\n",
              "                                         ingredients  \\\n",
              "0  200g dark chocolate , chopped|2 tbsp chocolate...   \n",
              "1  sunflower oil , for frying|2 large  potatoes ,...   \n",
              "2  1 tsp olive oil|1 onion , finely chopped|1 gre...   \n",
              "\n",
              "                                uniq_id         source          author  \\\n",
              "0  6619d1f2-7c2c-5ab0-85f8-b8a1c190915e  BBC Good Food  Good Food team   \n",
              "1  dc28ef65-01aa-527a-972d-0f959319e6ae  BBC Good Food    James Martin   \n",
              "2  f27090fa-5eaa-5472-8748-4954aa1ec802  BBC Good Food  Good Food team   \n",
              "\n",
              "  prep_time             published_date  \\\n",
              "0     PT10M  2020-02-17T15:47:46+00:00   \n",
              "1     PT25M  2012-10-09T04:20:39+00:00   \n",
              "2     PT10M  2011-06-14T01:36:59+00:00   \n",
              "\n",
              "                                            keywords total_ratings  \\\n",
              "0  bark, BBC Good Food team, Chocolate, Dessert, ...     5 ratings   \n",
              "1  2 of 5-a-day, Autumnal, Deer, Fibre, Five a da...    24 ratings   \n",
              "2   Josh Eagleton, 10-30 minutes, 30-60 minutes, ...    13 ratings   \n",
              "\n",
              "                                        instructions  \n",
              "0  Melt the chocolate in short bursts in the micr...  \n",
              "1  To make the sauce, heat 1 tbsp of the butter i...  \n",
              "2  Heat the oil in a large non-stick frying pan a...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ac2e750-f581-4ac2-a0f1-3179183f0895\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_time</th>\n",
              "      <th>cook_time</th>\n",
              "      <th>serving</th>\n",
              "      <th>crawled_at</th>\n",
              "      <th>description</th>\n",
              "      <th>title</th>\n",
              "      <th>url</th>\n",
              "      <th>nutritions_info</th>\n",
              "      <th>image</th>\n",
              "      <th>ingredients</th>\n",
              "      <th>uniq_id</th>\n",
              "      <th>source</th>\n",
              "      <th>author</th>\n",
              "      <th>prep_time</th>\n",
              "      <th>published_date</th>\n",
              "      <th>keywords</th>\n",
              "      <th>total_ratings</th>\n",
              "      <th>instructions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PT10M</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14</td>\n",
              "      <td>2021-12-17 08:46:25</td>\n",
              "      <td>Create a delicious homemade chocolate bark wit...</td>\n",
              "      <td>Easy chocolate bark</td>\n",
              "      <td>https://www.bbcgoodfood.com/recipes/easy-choco...</td>\n",
              "      <td>calories:116 calories | fatContent:7 grams fat...</td>\n",
              "      <td>https://images.immediate.co.uk/production/vola...</td>\n",
              "      <td>200g dark chocolate , chopped|2 tbsp chocolate...</td>\n",
              "      <td>6619d1f2-7c2c-5ab0-85f8-b8a1c190915e</td>\n",
              "      <td>BBC Good Food</td>\n",
              "      <td>Good Food team</td>\n",
              "      <td>PT10M</td>\n",
              "      <td>2020-02-17T15:47:46+00:00</td>\n",
              "      <td>bark, BBC Good Food team, Chocolate, Dessert, ...</td>\n",
              "      <td>5 ratings</td>\n",
              "      <td>Melt the chocolate in short bursts in the micr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PT55M</td>\n",
              "      <td>PT30M</td>\n",
              "      <td>2</td>\n",
              "      <td>2021-12-17 01:49:12</td>\n",
              "      <td>Steak and chips gets even more special with ra...</td>\n",
              "      <td>Venison steaks with stroganoff sauce &amp; shoestr...</td>\n",
              "      <td>https://www.bbcgoodfood.com/recipes/venison-st...</td>\n",
              "      <td>calories:719 calories | fatContent:33 grams fa...</td>\n",
              "      <td>https://images.immediate.co.uk/production/vola...</td>\n",
              "      <td>sunflower oil , for frying|2 large  potatoes ,...</td>\n",
              "      <td>dc28ef65-01aa-527a-972d-0f959319e6ae</td>\n",
              "      <td>BBC Good Food</td>\n",
              "      <td>James Martin</td>\n",
              "      <td>PT25M</td>\n",
              "      <td>2012-10-09T04:20:39+00:00</td>\n",
              "      <td>2 of 5-a-day, Autumnal, Deer, Fibre, Five a da...</td>\n",
              "      <td>24 ratings</td>\n",
              "      <td>To make the sauce, heat 1 tbsp of the butter i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PT30M</td>\n",
              "      <td>PT20M</td>\n",
              "      <td>4</td>\n",
              "      <td>2021-12-17 02:50:12</td>\n",
              "      <td>A dish with added feelgood factor - this vitam...</td>\n",
              "      <td>Mexican chicken &amp; wild rice soup</td>\n",
              "      <td>https://www.bbcgoodfood.com/recipes/mexican-ch...</td>\n",
              "      <td>calories:347 calories | fatContent:7 grams fat...</td>\n",
              "      <td>https://images.immediate.co.uk/production/vola...</td>\n",
              "      <td>1 tsp olive oil|1 onion , finely chopped|1 gre...</td>\n",
              "      <td>f27090fa-5eaa-5472-8748-4954aa1ec802</td>\n",
              "      <td>BBC Good Food</td>\n",
              "      <td>Good Food team</td>\n",
              "      <td>PT10M</td>\n",
              "      <td>2011-06-14T01:36:59+00:00</td>\n",
              "      <td>Josh Eagleton, 10-30 minutes, 30-60 minutes, ...</td>\n",
              "      <td>13 ratings</td>\n",
              "      <td>Heat the oil in a large non-stick frying pan a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ac2e750-f581-4ac2-a0f1-3179183f0895')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2ac2e750-f581-4ac2-a0f1-3179183f0895 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2ac2e750-f581-4ac2-a0f1-3179183f0895');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def time_to_minutes(dtime):\n",
        "    #print(dtime.head())\n",
        "    data=dtime.str.findall(r'\\d+').to_list()\n",
        "    minutes = []\n",
        "    for i in range(len(data)):\n",
        "        data_i = list(map(int, data[i]))\n",
        "        if len(data_i)==1:\n",
        "            if re.match(r'^PT', dtime.iloc[i]):\n",
        "                minutes.append(data_i[0])\n",
        "            else:\n",
        "                #print('1:',dtime.iloc[i],data_i)\n",
        "                minutes.append(data_i[0]*24*60)  \n",
        "\n",
        "        elif len(data_i)==2:\n",
        "            if re.match(r'^PT',dtime.iloc[i]):\n",
        "                minutes.append(data_i[0]*60+data_i[1])\n",
        "            else: \n",
        "                #print('2:',dtime.iloc[i],data_i)\n",
        "                minutes.append(data_i[0]*24*60+data_i[1]*60)\n",
        "        else:\n",
        "            #print('3:',dtime.iloc[i], data_i)\n",
        "            minutes.append(data_i[0]*24*60+data_i[1]*60+data_i[2])\n",
        "            \n",
        "    return minutes"
      ],
      "metadata": {
        "id": "KhPChsSVvfKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def date_to_timestamp(ddate):\n",
        "    ddate = pd.to_datetime(ddate).values.astype(np.int64)\n",
        "    return ddate"
      ],
      "metadata": {
        "id": "h4h1_vqpvjqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def serving_values(dd,debug_flag=0):\n",
        "    #print(dtime.head())\n",
        "    data=dd.str.findall(r'\\d+').to_list()\n",
        "    serving = []\n",
        "    for i in range(len(data)):\n",
        "        data_i = list(map(int, data[i]))\n",
        "        if (len(data_i)==0 or len(data_i)>3):\n",
        "            if debug_flag:\n",
        "                print('0 or >3:', dd.iloc[i], data_i)\n",
        "            serving.append(1)\n",
        "        elif len(data_i)==1:\n",
        "            serving.append(data_i[0])\n",
        "        elif len(data_i)==2:\n",
        "            if debug_flag:\n",
        "                print('2:',dd.iloc[i],data_i)\n",
        "            serving.append(sum(data_i)/len(data_i))\n",
        "        else:\n",
        "            if debug_flag:\n",
        "                print('3:',dd.iloc[i], data_i)\n",
        "            serving.append(data_i[0])\n",
        "            \n",
        "    return serving"
      ],
      "metadata": {
        "id": "T7cH1bBQvlC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_values_from_column(data):\n",
        "    data1 = data.tolist()\n",
        "    for i in range(len(data1)):\n",
        "        if data1[i] is None:\n",
        "            data1[i] = 0\n",
        "        else:\n",
        "            data1[i] = float(data1[i][0])\n",
        "    \n",
        "    return data1"
      ],
      "metadata": {
        "id": "E0ZnK2UgvpKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "def author_encode(data):\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    le.fit(data)\n",
        "    data = le.fit_transform(data)\n",
        "    return data, le"
      ],
      "metadata": {
        "id": "SRFid7r2vs4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def keywords_vectorizer(data):\n",
        "    vect = CountVectorizer().fit(data)\n",
        "    tdata = list(vect.transform(data).toarray())\n",
        "    return tdata, vect"
      ],
      "metadata": {
        "id": "00yk7nsgvt0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_lemmatize_text(data, debug_flag=0,rexp=r'[a-zA-Z][a-zA-Z]+'):\n",
        "    data = data.str.lower()\n",
        "    dtext=data.to_string(index=False)\n",
        "    tonolizer = nltk.RegexpTokenizer(rexp)\n",
        "    wtoken=tonolizer.tokenize(dtext)\n",
        "    if debug_flag:\n",
        "        dtoken = nltk.word_tokenize(dtext)\n",
        "        print('default:',len(dtoken),len(set(dtoken)))\n",
        "        tonolizer = nltk.RegexpTokenizer(r'\\w+')\n",
        "        dtoken=tonolizer.tokenize(dtext)\n",
        "        print('word w+', len(dtoken), len(set(dtoken)))\n",
        "        print('wordlen2+',len(wtoken), len(set(wtoken)))\n",
        "\n",
        "    tags = nltk.pos_tag(wtoken)\n",
        "    dtoken = [word for word, pos in tags if (pos=='NN' or pos=='NNP' or pos=='NNS' or pos=='NNPS')]\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    ltoken= [lemmatizer.lemmatize(word, wn.NOUN) for word, pos in tags if (pos=='NN' or pos=='NNP' or pos=='NNS' or pos=='NNPS')]\n",
        "    if debug_flag:\n",
        "        print('Noun only', len(dtoken), len(set(dtoken)))\n",
        "        print('lemmatizer:',len(ltoken), len(set(ltoken)))    \n",
        "        ddict = nltk.FreqDist(dtoken)\n",
        "        ddict = sorted(ddict.items(), key=lambda kv:[kv[1],kv[0]], reverse=True)\n",
        "        print(ddict[0:10])\n",
        "    \n",
        "    return ltoken"
      ],
      "metadata": {
        "id": "21QXyNJnvzuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ingredients_vectorizer(data, debug_flag=0):   \n",
        "    ltoken = tokenize_lemmatize_text(data)\n",
        "    mystop=['ml','kg','gram','tsp','tbsp','oz','pack','slices','self','lb','cut','tin','medium','small','large']\n",
        "\n",
        "    vect = CountVectorizer(stop_words=mystop,min_df=5)\n",
        "    vect.fit(ltoken)\n",
        "    data_vect = vect.transform(data).toarray()\n",
        "    \n",
        "    data=data.squeeze()\n",
        "    data = data.str.split(r'|', expand=True)\n",
        "    ncols = data.shape[1]\n",
        "    vct_num = []\n",
        "    for i in range(data.shape[0]):\n",
        "        nnn = ncols - data.iloc[i].isnull().sum()\n",
        "        if nnn>30 and debug_flag:\n",
        "            print(i, nnn)\n",
        "        vct_num.append(nnn)\n",
        "\n",
        "    return vct_num, data_vect, vect"
      ],
      "metadata": {
        "id": "clfsZiRSv3Iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def title_vectorizer(data):\n",
        "    ltoken = tokenize_lemmatize_text(data)\n",
        "    vect = CountVectorizer(min_df=3)\n",
        "    vect.fit(ltoken)\n",
        "    data_vect = vect.transform(data).toarray()\n",
        "    return data_vect, vect\n",
        "\n",
        "def text_vectorizer(data, min_df=3):\n",
        "    ltoken = tokenize_lemmatize_text(data,rexp=r'\\w+')\n",
        "    vect = TfidfVectorizer(min_df=min_df)\n",
        "    vect.fit(ltoken)\n",
        "    data_vect = vect.transform(data).toarray()\n",
        "    return data_vect, vect"
      ],
      "metadata": {
        "id": "XJgWjGMOv31F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handel_all_none_values(data, dropna_flag=0):\n",
        "    if dropna_flag:\n",
        "        data = data.dropna(how='any',axis=0)\n",
        "        return data\n",
        "    num_null=[data[col].isnull().sum() for col in data.columns]\n",
        "    print('Column Names:', data.columns)\n",
        "    print('Numbers of NULLs/column', num_null)\n",
        "    \n",
        "    for col in ['total_time']:\n",
        "        data[col] = data[col].fillna('PT0M')\n",
        "    data['serving']         = data['serving'].fillna('0')\n",
        "    data['nutritions_info'] = data['nutritions_info'].fillna('calories:0 calories')\n",
        "    data['ingredients']     = data['ingredients'].fillna('noingredients')\n",
        "    data['keywords']        = data['keywords'].fillna('nokeywords')\n",
        "    data['total_ratings']   = data['total_ratings'].fillna('0 reviews')\n",
        "    \n",
        "    print('Number of NULLs at return = ', data.isnull().sum().sum())\n",
        "    print('Data Sizes =', data.shape)\n",
        "    return data\n",
        "\n",
        "def prepare_and_clean_data_model(df):\n",
        "    df = handel_all_none_values(df)\n",
        "\n",
        "    #check for NULL raw data\n",
        "    print('# of nan =', df.isnull().sum().sum())\n",
        "\n",
        "    # change datatype \n",
        "    df['total_ratings']=df['total_ratings'].str.split().str[0].astype(int)\n",
        "    df['total_time'] = time_to_minutes(df['total_time'])\n",
        "    df['published_date'] = date_to_timestamp(df['published_date'])\n",
        "    df['serving'] = serving_values(df['serving'])\n",
        "    df['author'], author_le = author_encode(df['author'])\n",
        "    data1 = nutrition_information_values(df['nutritions_info'])\n",
        "    df =df.merge(data1,left_index=True,right_index=True)\n",
        "    df.drop(columns=['nutritions_info'],inplace=True)\n",
        "\n",
        "    # tokenization \n",
        "    df['keywords'], keywords_vect = keywords_vectorizer(df['keywords'])\n",
        "    df['ingredients_counts'],df_ingre, ingre_vect = ingredients_vectorizer(df['ingredients'])\n",
        "    df_title, title_vect = title_vectorizer(df['title'])\n",
        "    df_descr, descr_vect = text_vectorizer(df['description'],min_df=7)\n",
        "    \n",
        "    df_text = [df_title, df_ingre, df_descr]\n",
        "    vect_text = [title_vect, ingre_vect, descr_vect]\n",
        "    return df, df_text, vect_text\n",
        "\n",
        "#df = pd.read_csv('/content/drive/MyDrive/food_recipes_data.csv')\n",
        "#df = pd.read_csv('/content/drive/MyDrive/865 Group/food_recipes_data.csv') #Penny\n",
        "\n",
        "df, df_text, vect_text = prepare_and_clean_data_model(df)\n",
        "\n",
        "print('df shape=',df.shape)\n",
        "print('title:',df_text[0].shape)\n",
        "print('ingredients:',df_text[1].shape)\n",
        "print('description:',df_text[1].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "9XwgZrG_xICc",
        "outputId": "0cd2fa8f-4b47-4cad-81b5-0d9c949e709d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column Names: Index(['total_time', 'cook_time', 'serving', 'crawled_at', 'description',\n",
            "       'title', 'url', 'nutritions_info', 'image', 'ingredients', 'uniq_id',\n",
            "       'source', 'author', 'prep_time', 'published_date', 'keywords',\n",
            "       'total_ratings', 'instructions'],\n",
            "      dtype='object')\n",
            "Numbers of NULLs/column [2011, 3859, 2076, 0, 0, 0, 0, 2197, 0, 137, 0, 0, 0, 3090, 0, 360, 53, 1959]\n",
            "Number of NULLs at return =  8908\n",
            "Data Sizes = (14200, 18)\n",
            "# of nan = 8908\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-d5fa6001acb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m#df = pd.read_csv('/content/drive/MyDrive/865 Group/food_recipes_data.csv') #Penny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvect_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_and_clean_data_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'df shape='\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-d5fa6001acb9>\u001b[0m in \u001b[0;36mprepare_and_clean_data_model\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'serving'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserving_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'serving'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'author'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthor_le\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauthor_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'author'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mdata1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnutrition_information_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nutritions_info'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nutritions_info'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nutrition_information_values' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#delete column that we don't use\n",
        "del df['url']\n",
        "del df['crawled_at']\n",
        "del df['prep_time']\n",
        "del df['cook_time']\n",
        "del df['uniq_id']\n",
        "del df['source']"
      ],
      "metadata": {
        "id": "ypLxqrjrle9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del df['instructions']"
      ],
      "metadata": {
        "id": "Kzt-ftJvuZC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "JASQiZ8Kkj6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8dUn_oa5ukP"
      },
      "outputs": [],
      "source": [
        "df.isna().sum()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}